{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uchau\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\uchau\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Using a model fine-tuned for BOOLQ\n",
    "model_name = 'lewtun/bert-base-uncased-finetuned-boolq'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # BOOLQ has 2 labels: true and false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a model fine-tuned for BOOLQ\n",
    "model_name = 'lewtun/bert-base-uncased-finetuned-boolq'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # BOOLQ has 2 labels: true and false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BOOLQ dataset\n",
    "boolq = load_dataset('super_glue', 'boolq', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples['passage'], examples['question'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "encoded_dataset = boolq.map(preprocess, batched=True)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uchau\\AppData\\Local\\Temp\\ipykernel_4900\\2195451347.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy_metric = load_metric(\"accuracy\")\n",
      "c:\\Users\\uchau\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\uchau\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1453: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the metric and trainer\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)\n",
    "    f1_weighted = f1_score(labels, preds, average='weighted')\n",
    "    f1_per_class = f1_score(labels, preds, average=None)\n",
    "    return {'accuracy': acc['accuracy'], 'f1_weighted': f1_weighted, 'f1_per_class': f1_per_class}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    do_train=False,                  # don't perform training\n",
    "    do_eval=True,                    # perform evaluation\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    no_cuda=True                     # Disable GPU for debugging\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                     # the pre-trained model\n",
    "    args=training_args,              # training arguments\n",
    "    eval_dataset=encoded_dataset['validation'], # evaluation dataset (test set)\n",
    "    compute_metrics=compute_metrics  # evaluation metric function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55452302daf345c792deb76bea976c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.59163273 0.7126856 ]\" of type <class 'numpy.ndarray'> for key \"eval/f1_per_class\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.3%\n",
      "Weighted F1 Score: 66.7%\n",
      "F1 Score for each class: [59.16327286 71.26855952]\n"
     ]
    }
   ],
   "source": [
    "acc = eval_result['eval_accuracy'] * 100\n",
    "f1_weighted = eval_result['eval_f1_weighted'] * 100\n",
    "f1_per_class = eval_result['eval_f1_per_class'] * 100\n",
    "\n",
    "print(f\"Accuracy: {acc:.1f}%\")\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.1f}%\")\n",
    "print(f\"F1 Score for each class: {f1_per_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
